{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNPRTRrY6JKwObLO/2GWxJL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"63s0uzcJGre9","executionInfo":{"status":"ok","timestamp":1704699723933,"user_tz":-420,"elapsed":5,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YlkxB2aGGy6","executionInfo":{"status":"ok","timestamp":1704699747765,"user_tz":-420,"elapsed":23836,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"10208b22-5b11-46a3-9bcc-a7126d287330"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/DeepLearning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrNRJDgxGPYk","executionInfo":{"status":"ok","timestamp":1704699747765,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"e8d78bfb-04f5-4f87-a22e-d6713c8d7e80"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DeepLearning\n"]}]},{"cell_type":"code","source":["# !git clone https://github.com/leimao/PyTorch-Static-Quantization.git"],"metadata":{"id":"BSsv9AH2GHLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd PyTorch-Static-Quantization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwFZ7vJZGNfW","executionInfo":{"status":"ok","timestamp":1704699747765,"user_tz":-420,"elapsed":9,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"9740bf51-7afa-47cd-b6fd-b5a94121822d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DeepLearning/PyTorch-Static-Quantization\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFSeh2bwGXZT","executionInfo":{"status":"ok","timestamp":1704699747766,"user_tz":-420,"elapsed":8,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"d68b2776-62e4-4e0e-b65e-a27a39233f32"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["cifar.py  \u001b[0m\u001b[01;34mdocker\u001b[0m/     \u001b[01;34m__pycache__\u001b[0m/                       README.md  \u001b[01;34msaved_models\u001b[0m/\n","\u001b[01;34mdata\u001b[0m/     LICENSE.md  PyTorch-Static-Quantization.ipynb  resnet.py\n"]}]},{"cell_type":"code","source":["!python cifar.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBUcNoVKGa5Y","executionInfo":{"status":"ok","timestamp":1704556246754,"user_tz":-420,"elapsed":4018725,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"ed9f2421-6f22-4d18-902d-b1a0ee9232eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Epoch: -1 Eval Loss: 2.325 Eval Acc: 0.098\n","Epoch: 000 Train Loss: 2.031 Train Acc: 0.324 Eval Loss: 1.623 Eval Acc: 0.425\n","Epoch: 001 Train Loss: 1.479 Train Acc: 0.462 Eval Loss: 1.270 Eval Acc: 0.540\n","Epoch: 002 Train Loss: 1.260 Train Acc: 0.547 Eval Loss: 1.096 Eval Acc: 0.613\n","Epoch: 003 Train Loss: 1.117 Train Acc: 0.604 Eval Loss: 1.089 Eval Acc: 0.622\n","Epoch: 004 Train Loss: 1.018 Train Acc: 0.641 Eval Loss: 0.981 Eval Acc: 0.661\n","Epoch: 005 Train Loss: 0.942 Train Acc: 0.669 Eval Loss: 0.894 Eval Acc: 0.687\n","Epoch: 006 Train Loss: 0.881 Train Acc: 0.694 Eval Loss: 0.858 Eval Acc: 0.701\n","Epoch: 007 Train Loss: 0.841 Train Acc: 0.705 Eval Loss: 0.795 Eval Acc: 0.717\n","Epoch: 008 Train Loss: 0.787 Train Acc: 0.727 Eval Loss: 0.746 Eval Acc: 0.744\n","Epoch: 009 Train Loss: 0.760 Train Acc: 0.736 Eval Loss: 0.761 Eval Acc: 0.737\n","Epoch: 010 Train Loss: 0.729 Train Acc: 0.748 Eval Loss: 0.771 Eval Acc: 0.734\n","Epoch: 011 Train Loss: 0.700 Train Acc: 0.758 Eval Loss: 0.722 Eval Acc: 0.753\n","Epoch: 012 Train Loss: 0.678 Train Acc: 0.767 Eval Loss: 0.685 Eval Acc: 0.763\n","Epoch: 013 Train Loss: 0.659 Train Acc: 0.771 Eval Loss: 0.734 Eval Acc: 0.755\n","Epoch: 014 Train Loss: 0.640 Train Acc: 0.777 Eval Loss: 0.650 Eval Acc: 0.783\n","Epoch: 015 Train Loss: 0.618 Train Acc: 0.787 Eval Loss: 0.673 Eval Acc: 0.771\n","Epoch: 016 Train Loss: 0.609 Train Acc: 0.788 Eval Loss: 0.676 Eval Acc: 0.777\n","Epoch: 017 Train Loss: 0.596 Train Acc: 0.792 Eval Loss: 0.682 Eval Acc: 0.771\n","Epoch: 018 Train Loss: 0.580 Train Acc: 0.798 Eval Loss: 0.630 Eval Acc: 0.788\n","Epoch: 019 Train Loss: 0.571 Train Acc: 0.802 Eval Loss: 0.602 Eval Acc: 0.794\n","Epoch: 020 Train Loss: 0.560 Train Acc: 0.806 Eval Loss: 0.636 Eval Acc: 0.786\n","Epoch: 021 Train Loss: 0.544 Train Acc: 0.811 Eval Loss: 0.687 Eval Acc: 0.766\n","Epoch: 022 Train Loss: 0.540 Train Acc: 0.811 Eval Loss: 0.628 Eval Acc: 0.791\n","Epoch: 023 Train Loss: 0.535 Train Acc: 0.814 Eval Loss: 0.687 Eval Acc: 0.774\n","Epoch: 024 Train Loss: 0.522 Train Acc: 0.817 Eval Loss: 0.635 Eval Acc: 0.789\n","Epoch: 025 Train Loss: 0.517 Train Acc: 0.821 Eval Loss: 0.624 Eval Acc: 0.792\n","Epoch: 026 Train Loss: 0.508 Train Acc: 0.823 Eval Loss: 0.576 Eval Acc: 0.803\n","Epoch: 027 Train Loss: 0.495 Train Acc: 0.828 Eval Loss: 0.591 Eval Acc: 0.801\n","Epoch: 028 Train Loss: 0.495 Train Acc: 0.828 Eval Loss: 0.596 Eval Acc: 0.800\n","Epoch: 029 Train Loss: 0.486 Train Acc: 0.831 Eval Loss: 0.582 Eval Acc: 0.805\n","Epoch: 030 Train Loss: 0.478 Train Acc: 0.835 Eval Loss: 0.605 Eval Acc: 0.797\n","Epoch: 031 Train Loss: 0.480 Train Acc: 0.832 Eval Loss: 0.570 Eval Acc: 0.807\n","Epoch: 032 Train Loss: 0.474 Train Acc: 0.836 Eval Loss: 0.602 Eval Acc: 0.801\n","Epoch: 033 Train Loss: 0.458 Train Acc: 0.841 Eval Loss: 0.572 Eval Acc: 0.811\n","Epoch: 034 Train Loss: 0.461 Train Acc: 0.839 Eval Loss: 0.572 Eval Acc: 0.813\n","Epoch: 035 Train Loss: 0.452 Train Acc: 0.844 Eval Loss: 0.611 Eval Acc: 0.802\n","Epoch: 036 Train Loss: 0.453 Train Acc: 0.841 Eval Loss: 0.582 Eval Acc: 0.814\n","Epoch: 037 Train Loss: 0.449 Train Acc: 0.843 Eval Loss: 0.569 Eval Acc: 0.812\n","Epoch: 038 Train Loss: 0.444 Train Acc: 0.845 Eval Loss: 0.559 Eval Acc: 0.818\n","Epoch: 039 Train Loss: 0.443 Train Acc: 0.845 Eval Loss: 0.592 Eval Acc: 0.812\n","Epoch: 040 Train Loss: 0.430 Train Acc: 0.849 Eval Loss: 0.585 Eval Acc: 0.814\n","Epoch: 041 Train Loss: 0.438 Train Acc: 0.848 Eval Loss: 0.579 Eval Acc: 0.806\n","Epoch: 042 Train Loss: 0.432 Train Acc: 0.850 Eval Loss: 0.552 Eval Acc: 0.816\n","Epoch: 043 Train Loss: 0.423 Train Acc: 0.853 Eval Loss: 0.559 Eval Acc: 0.813\n","Epoch: 044 Train Loss: 0.424 Train Acc: 0.850 Eval Loss: 0.560 Eval Acc: 0.817\n","Epoch: 045 Train Loss: 0.419 Train Acc: 0.853 Eval Loss: 0.566 Eval Acc: 0.814\n","Epoch: 046 Train Loss: 0.419 Train Acc: 0.852 Eval Loss: 0.582 Eval Acc: 0.810\n","Epoch: 047 Train Loss: 0.413 Train Acc: 0.855 Eval Loss: 0.602 Eval Acc: 0.805\n","Epoch: 048 Train Loss: 0.405 Train Acc: 0.858 Eval Loss: 0.546 Eval Acc: 0.818\n","Epoch: 049 Train Loss: 0.409 Train Acc: 0.857 Eval Loss: 0.531 Eval Acc: 0.824\n","Epoch: 050 Train Loss: 0.401 Train Acc: 0.860 Eval Loss: 0.580 Eval Acc: 0.814\n","Epoch: 051 Train Loss: 0.404 Train Acc: 0.859 Eval Loss: 0.548 Eval Acc: 0.822\n","Epoch: 052 Train Loss: 0.399 Train Acc: 0.861 Eval Loss: 0.586 Eval Acc: 0.816\n","Epoch: 053 Train Loss: 0.399 Train Acc: 0.861 Eval Loss: 0.559 Eval Acc: 0.812\n","Epoch: 054 Train Loss: 0.392 Train Acc: 0.863 Eval Loss: 0.550 Eval Acc: 0.819\n","Epoch: 055 Train Loss: 0.392 Train Acc: 0.864 Eval Loss: 0.578 Eval Acc: 0.815\n","Epoch: 056 Train Loss: 0.388 Train Acc: 0.864 Eval Loss: 0.605 Eval Acc: 0.806\n","Epoch: 057 Train Loss: 0.383 Train Acc: 0.867 Eval Loss: 0.548 Eval Acc: 0.820\n","Epoch: 058 Train Loss: 0.389 Train Acc: 0.864 Eval Loss: 0.555 Eval Acc: 0.816\n","Epoch: 059 Train Loss: 0.386 Train Acc: 0.866 Eval Loss: 0.610 Eval Acc: 0.804\n","Epoch: 060 Train Loss: 0.384 Train Acc: 0.866 Eval Loss: 0.559 Eval Acc: 0.820\n","Epoch: 061 Train Loss: 0.378 Train Acc: 0.868 Eval Loss: 0.563 Eval Acc: 0.822\n","Epoch: 062 Train Loss: 0.383 Train Acc: 0.865 Eval Loss: 0.539 Eval Acc: 0.831\n","Epoch: 063 Train Loss: 0.375 Train Acc: 0.867 Eval Loss: 0.550 Eval Acc: 0.820\n","Epoch: 064 Train Loss: 0.378 Train Acc: 0.868 Eval Loss: 0.640 Eval Acc: 0.794\n","Epoch: 065 Train Loss: 0.375 Train Acc: 0.870 Eval Loss: 0.669 Eval Acc: 0.793\n","Epoch: 066 Train Loss: 0.375 Train Acc: 0.869 Eval Loss: 0.606 Eval Acc: 0.810\n","Epoch: 067 Train Loss: 0.375 Train Acc: 0.871 Eval Loss: 0.513 Eval Acc: 0.833\n","Epoch: 068 Train Loss: 0.368 Train Acc: 0.872 Eval Loss: 0.568 Eval Acc: 0.817\n","Epoch: 069 Train Loss: 0.371 Train Acc: 0.871 Eval Loss: 0.534 Eval Acc: 0.827\n","Epoch: 070 Train Loss: 0.364 Train Acc: 0.872 Eval Loss: 0.595 Eval Acc: 0.808\n","Epoch: 071 Train Loss: 0.367 Train Acc: 0.871 Eval Loss: 0.511 Eval Acc: 0.834\n","Epoch: 072 Train Loss: 0.364 Train Acc: 0.873 Eval Loss: 0.559 Eval Acc: 0.819\n","Epoch: 073 Train Loss: 0.367 Train Acc: 0.872 Eval Loss: 0.559 Eval Acc: 0.822\n","Epoch: 074 Train Loss: 0.359 Train Acc: 0.874 Eval Loss: 0.599 Eval Acc: 0.815\n","Epoch: 075 Train Loss: 0.360 Train Acc: 0.876 Eval Loss: 0.524 Eval Acc: 0.835\n","Epoch: 076 Train Loss: 0.356 Train Acc: 0.876 Eval Loss: 0.541 Eval Acc: 0.829\n","Epoch: 077 Train Loss: 0.356 Train Acc: 0.876 Eval Loss: 0.574 Eval Acc: 0.813\n","Epoch: 078 Train Loss: 0.357 Train Acc: 0.876 Eval Loss: 0.605 Eval Acc: 0.808\n","Epoch: 079 Train Loss: 0.350 Train Acc: 0.877 Eval Loss: 0.569 Eval Acc: 0.818\n","Epoch: 080 Train Loss: 0.356 Train Acc: 0.875 Eval Loss: 0.606 Eval Acc: 0.808\n","Epoch: 081 Train Loss: 0.351 Train Acc: 0.877 Eval Loss: 0.541 Eval Acc: 0.826\n","Epoch: 082 Train Loss: 0.349 Train Acc: 0.878 Eval Loss: 0.531 Eval Acc: 0.829\n","Epoch: 083 Train Loss: 0.351 Train Acc: 0.876 Eval Loss: 0.591 Eval Acc: 0.816\n","Epoch: 084 Train Loss: 0.347 Train Acc: 0.878 Eval Loss: 0.592 Eval Acc: 0.813\n","Epoch: 085 Train Loss: 0.351 Train Acc: 0.876 Eval Loss: 0.526 Eval Acc: 0.832\n","Epoch: 086 Train Loss: 0.351 Train Acc: 0.878 Eval Loss: 0.559 Eval Acc: 0.819\n","Epoch: 087 Train Loss: 0.344 Train Acc: 0.879 Eval Loss: 0.551 Eval Acc: 0.822\n","Epoch: 088 Train Loss: 0.347 Train Acc: 0.879 Eval Loss: 0.592 Eval Acc: 0.813\n","Epoch: 089 Train Loss: 0.344 Train Acc: 0.877 Eval Loss: 0.513 Eval Acc: 0.835\n","Epoch: 090 Train Loss: 0.340 Train Acc: 0.880 Eval Loss: 0.551 Eval Acc: 0.825\n","Epoch: 091 Train Loss: 0.341 Train Acc: 0.881 Eval Loss: 0.576 Eval Acc: 0.817\n","Epoch: 092 Train Loss: 0.341 Train Acc: 0.881 Eval Loss: 0.550 Eval Acc: 0.825\n","Epoch: 093 Train Loss: 0.340 Train Acc: 0.883 Eval Loss: 0.566 Eval Acc: 0.823\n","Epoch: 094 Train Loss: 0.339 Train Acc: 0.881 Eval Loss: 0.546 Eval Acc: 0.826\n","Epoch: 095 Train Loss: 0.337 Train Acc: 0.882 Eval Loss: 0.602 Eval Acc: 0.811\n","Epoch: 096 Train Loss: 0.340 Train Acc: 0.881 Eval Loss: 0.535 Eval Acc: 0.828\n","Epoch: 097 Train Loss: 0.339 Train Acc: 0.882 Eval Loss: 0.562 Eval Acc: 0.822\n","Epoch: 098 Train Loss: 0.338 Train Acc: 0.881 Eval Loss: 0.571 Eval Acc: 0.820\n","Epoch: 099 Train Loss: 0.339 Train Acc: 0.881 Eval Loss: 0.590 Eval Acc: 0.812\n","Epoch: 100 Train Loss: 0.228 Train Acc: 0.921 Eval Loss: 0.446 Eval Acc: 0.865\n","Epoch: 101 Train Loss: 0.177 Train Acc: 0.938 Eval Loss: 0.451 Eval Acc: 0.868\n","Epoch: 102 Train Loss: 0.167 Train Acc: 0.941 Eval Loss: 0.449 Eval Acc: 0.871\n","Epoch: 103 Train Loss: 0.151 Train Acc: 0.947 Eval Loss: 0.449 Eval Acc: 0.871\n","Epoch: 104 Train Loss: 0.144 Train Acc: 0.948 Eval Loss: 0.463 Eval Acc: 0.868\n","Epoch: 105 Train Loss: 0.138 Train Acc: 0.951 Eval Loss: 0.462 Eval Acc: 0.870\n","Epoch: 106 Train Loss: 0.131 Train Acc: 0.953 Eval Loss: 0.466 Eval Acc: 0.870\n","Epoch: 107 Train Loss: 0.127 Train Acc: 0.955 Eval Loss: 0.465 Eval Acc: 0.870\n","Epoch: 108 Train Loss: 0.122 Train Acc: 0.957 Eval Loss: 0.469 Eval Acc: 0.870\n","Epoch: 109 Train Loss: 0.117 Train Acc: 0.959 Eval Loss: 0.474 Eval Acc: 0.874\n","Epoch: 110 Train Loss: 0.114 Train Acc: 0.959 Eval Loss: 0.476 Eval Acc: 0.873\n","Epoch: 111 Train Loss: 0.109 Train Acc: 0.961 Eval Loss: 0.481 Eval Acc: 0.874\n","Epoch: 112 Train Loss: 0.104 Train Acc: 0.963 Eval Loss: 0.492 Eval Acc: 0.872\n","Epoch: 113 Train Loss: 0.103 Train Acc: 0.964 Eval Loss: 0.487 Eval Acc: 0.873\n","Epoch: 114 Train Loss: 0.098 Train Acc: 0.966 Eval Loss: 0.497 Eval Acc: 0.872\n","Epoch: 115 Train Loss: 0.094 Train Acc: 0.967 Eval Loss: 0.513 Eval Acc: 0.870\n","Epoch: 116 Train Loss: 0.095 Train Acc: 0.966 Eval Loss: 0.504 Eval Acc: 0.871\n","Epoch: 117 Train Loss: 0.093 Train Acc: 0.967 Eval Loss: 0.505 Eval Acc: 0.870\n","Epoch: 118 Train Loss: 0.089 Train Acc: 0.968 Eval Loss: 0.512 Eval Acc: 0.872\n","Epoch: 119 Train Loss: 0.087 Train Acc: 0.970 Eval Loss: 0.513 Eval Acc: 0.873\n","Epoch: 120 Train Loss: 0.085 Train Acc: 0.969 Eval Loss: 0.513 Eval Acc: 0.872\n","Epoch: 121 Train Loss: 0.086 Train Acc: 0.970 Eval Loss: 0.524 Eval Acc: 0.870\n","Epoch: 122 Train Loss: 0.081 Train Acc: 0.972 Eval Loss: 0.521 Eval Acc: 0.873\n","Epoch: 123 Train Loss: 0.081 Train Acc: 0.971 Eval Loss: 0.526 Eval Acc: 0.871\n","Epoch: 124 Train Loss: 0.077 Train Acc: 0.973 Eval Loss: 0.536 Eval Acc: 0.869\n","Epoch: 125 Train Loss: 0.076 Train Acc: 0.974 Eval Loss: 0.531 Eval Acc: 0.873\n","Epoch: 126 Train Loss: 0.075 Train Acc: 0.973 Eval Loss: 0.540 Eval Acc: 0.873\n","Epoch: 127 Train Loss: 0.074 Train Acc: 0.973 Eval Loss: 0.525 Eval Acc: 0.872\n","Epoch: 128 Train Loss: 0.073 Train Acc: 0.974 Eval Loss: 0.536 Eval Acc: 0.870\n","Epoch: 129 Train Loss: 0.071 Train Acc: 0.975 Eval Loss: 0.549 Eval Acc: 0.869\n","Epoch: 130 Train Loss: 0.068 Train Acc: 0.976 Eval Loss: 0.553 Eval Acc: 0.874\n","Epoch: 131 Train Loss: 0.068 Train Acc: 0.976 Eval Loss: 0.572 Eval Acc: 0.869\n","Epoch: 132 Train Loss: 0.068 Train Acc: 0.976 Eval Loss: 0.564 Eval Acc: 0.867\n","Epoch: 133 Train Loss: 0.067 Train Acc: 0.976 Eval Loss: 0.567 Eval Acc: 0.870\n","Epoch: 134 Train Loss: 0.065 Train Acc: 0.977 Eval Loss: 0.572 Eval Acc: 0.869\n","Epoch: 135 Train Loss: 0.062 Train Acc: 0.977 Eval Loss: 0.570 Eval Acc: 0.867\n","Epoch: 136 Train Loss: 0.065 Train Acc: 0.977 Eval Loss: 0.562 Eval Acc: 0.871\n","Epoch: 137 Train Loss: 0.063 Train Acc: 0.977 Eval Loss: 0.578 Eval Acc: 0.869\n","Epoch: 138 Train Loss: 0.062 Train Acc: 0.978 Eval Loss: 0.581 Eval Acc: 0.870\n","Epoch: 139 Train Loss: 0.063 Train Acc: 0.978 Eval Loss: 0.581 Eval Acc: 0.868\n","Epoch: 140 Train Loss: 0.061 Train Acc: 0.979 Eval Loss: 0.586 Eval Acc: 0.873\n","Epoch: 141 Train Loss: 0.056 Train Acc: 0.980 Eval Loss: 0.597 Eval Acc: 0.870\n","Epoch: 142 Train Loss: 0.057 Train Acc: 0.979 Eval Loss: 0.587 Eval Acc: 0.870\n","Epoch: 143 Train Loss: 0.059 Train Acc: 0.979 Eval Loss: 0.593 Eval Acc: 0.869\n","Epoch: 144 Train Loss: 0.057 Train Acc: 0.980 Eval Loss: 0.575 Eval Acc: 0.872\n","Epoch: 145 Train Loss: 0.059 Train Acc: 0.979 Eval Loss: 0.589 Eval Acc: 0.870\n","Epoch: 146 Train Loss: 0.054 Train Acc: 0.981 Eval Loss: 0.588 Eval Acc: 0.872\n","Epoch: 147 Train Loss: 0.054 Train Acc: 0.981 Eval Loss: 0.584 Eval Acc: 0.871\n","Epoch: 148 Train Loss: 0.054 Train Acc: 0.981 Eval Loss: 0.587 Eval Acc: 0.874\n","Epoch: 149 Train Loss: 0.055 Train Acc: 0.981 Eval Loss: 0.606 Eval Acc: 0.873\n","Epoch: 150 Train Loss: 0.045 Train Acc: 0.985 Eval Loss: 0.587 Eval Acc: 0.876\n","Epoch: 151 Train Loss: 0.041 Train Acc: 0.986 Eval Loss: 0.584 Eval Acc: 0.876\n","Epoch: 152 Train Loss: 0.040 Train Acc: 0.986 Eval Loss: 0.578 Eval Acc: 0.877\n","Epoch: 153 Train Loss: 0.039 Train Acc: 0.987 Eval Loss: 0.581 Eval Acc: 0.876\n","Epoch: 154 Train Loss: 0.035 Train Acc: 0.988 Eval Loss: 0.582 Eval Acc: 0.878\n","Epoch: 155 Train Loss: 0.034 Train Acc: 0.988 Eval Loss: 0.581 Eval Acc: 0.878\n","Epoch: 156 Train Loss: 0.035 Train Acc: 0.988 Eval Loss: 0.583 Eval Acc: 0.878\n","Epoch: 157 Train Loss: 0.033 Train Acc: 0.989 Eval Loss: 0.583 Eval Acc: 0.877\n","Epoch: 158 Train Loss: 0.033 Train Acc: 0.989 Eval Loss: 0.585 Eval Acc: 0.877\n","Epoch: 159 Train Loss: 0.033 Train Acc: 0.989 Eval Loss: 0.581 Eval Acc: 0.876\n","Epoch: 160 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.588 Eval Acc: 0.879\n","Epoch: 161 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.594 Eval Acc: 0.877\n","Epoch: 162 Train Loss: 0.031 Train Acc: 0.990 Eval Loss: 0.590 Eval Acc: 0.878\n","Epoch: 163 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.591 Eval Acc: 0.876\n","Epoch: 164 Train Loss: 0.031 Train Acc: 0.989 Eval Loss: 0.596 Eval Acc: 0.876\n","Epoch: 165 Train Loss: 0.029 Train Acc: 0.990 Eval Loss: 0.598 Eval Acc: 0.876\n","Epoch: 166 Train Loss: 0.030 Train Acc: 0.990 Eval Loss: 0.600 Eval Acc: 0.878\n","Epoch: 167 Train Loss: 0.029 Train Acc: 0.990 Eval Loss: 0.606 Eval Acc: 0.876\n","Epoch: 168 Train Loss: 0.028 Train Acc: 0.990 Eval Loss: 0.601 Eval Acc: 0.876\n","Epoch: 169 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.609 Eval Acc: 0.879\n","Epoch: 170 Train Loss: 0.028 Train Acc: 0.990 Eval Loss: 0.611 Eval Acc: 0.878\n","Epoch: 171 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.608 Eval Acc: 0.878\n","Epoch: 172 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.610 Eval Acc: 0.877\n","Epoch: 173 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.609 Eval Acc: 0.878\n","Epoch: 174 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.615 Eval Acc: 0.876\n","Epoch: 175 Train Loss: 0.027 Train Acc: 0.992 Eval Loss: 0.619 Eval Acc: 0.877\n","Epoch: 176 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.619 Eval Acc: 0.877\n","Epoch: 177 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.619 Eval Acc: 0.877\n","Epoch: 178 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.622 Eval Acc: 0.876\n","Epoch: 179 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.619 Eval Acc: 0.876\n","Epoch: 180 Train Loss: 0.026 Train Acc: 0.992 Eval Loss: 0.620 Eval Acc: 0.876\n","Epoch: 181 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.622 Eval Acc: 0.877\n","Epoch: 182 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.621 Eval Acc: 0.878\n","Epoch: 183 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.622 Eval Acc: 0.877\n","Epoch: 184 Train Loss: 0.025 Train Acc: 0.991 Eval Loss: 0.629 Eval Acc: 0.877\n","Epoch: 185 Train Loss: 0.025 Train Acc: 0.992 Eval Loss: 0.628 Eval Acc: 0.877\n","Epoch: 186 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.623 Eval Acc: 0.877\n","Epoch: 187 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.635 Eval Acc: 0.879\n","Epoch: 188 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.631 Eval Acc: 0.877\n","Epoch: 189 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.633 Eval Acc: 0.877\n","Epoch: 190 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.637 Eval Acc: 0.877\n","Epoch: 191 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.633 Eval Acc: 0.878\n","Epoch: 192 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.638 Eval Acc: 0.877\n","Epoch: 193 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.633 Eval Acc: 0.876\n","Epoch: 194 Train Loss: 0.022 Train Acc: 0.992 Eval Loss: 0.641 Eval Acc: 0.877\n","Epoch: 195 Train Loss: 0.023 Train Acc: 0.993 Eval Loss: 0.638 Eval Acc: 0.879\n","Epoch: 196 Train Loss: 0.022 Train Acc: 0.992 Eval Loss: 0.641 Eval Acc: 0.878\n","Epoch: 197 Train Loss: 0.022 Train Acc: 0.993 Eval Loss: 0.639 Eval Acc: 0.878\n","Epoch: 198 Train Loss: 0.022 Train Acc: 0.993 Eval Loss: 0.648 Eval Acc: 0.876\n","Epoch: 199 Train Loss: 0.023 Train Acc: 0.993 Eval Loss: 0.644 Eval Acc: 0.877\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n","ResNet(\n","  (conv1): ConvReLU2d(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n","    (1): ReLU(inplace=True)\n","  )\n","  (bn1): Identity()\n","  (relu): Identity()\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n","        (1): Identity()\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n","        (1): Identity()\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n","        (1): Identity()\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n","QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n","/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n","  warnings.warn(\n","QuantizedResNet18(\n","  (quant): Quantize(scale=tensor([0.0374]), zero_point=tensor([57]), dtype=torch.quint8)\n","  (dequant): DeQuantize()\n","  (model_fp32): ResNet(\n","    (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.055078212171792984, zero_point=0, padding=(3, 3))\n","    (bn1): Identity()\n","    (relu): Identity()\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.028899412602186203, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07347884774208069, zero_point=70, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.09448865801095963, zero_point=45\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.028067925944924355, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.06587903201580048, zero_point=72, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.09615691006183624, zero_point=51\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.024324238300323486, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05666455626487732, zero_point=62, padding=(1, 1))\n","        (bn2): Identity()\n","        (downsample): Sequential(\n","          (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.04360596090555191, zero_point=59)\n","          (1): Identity()\n","        )\n","        (skip_add): QFunctional(\n","          scale=0.07108420133590698, zero_point=63\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.02060083858668804, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05236617103219032, zero_point=71, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.0747596025466919, zero_point=52\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.018845127895474434, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.03338520601391792, zero_point=70, padding=(1, 1))\n","        (bn2): Identity()\n","        (downsample): Sequential(\n","          (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.020058905705809593, zero_point=60)\n","          (1): Identity()\n","        )\n","        (skip_add): QFunctional(\n","          scale=0.03748178854584694, zero_point=69\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0039498647674918175, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.017515601590275764, zero_point=75, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.024873925372958183, zero_point=44\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.006411455571651459, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.019863886758685112, zero_point=48, padding=(1, 1))\n","        (bn2): Identity()\n","        (downsample): Sequential(\n","          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.028648119419813156, zero_point=55)\n","          (1): Identity()\n","        )\n","        (skip_add): QFunctional(\n","          scale=0.03676297143101692, zero_point=51\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.0011141408467665315, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.012289219535887241, zero_point=81, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.029921066015958786, zero_point=25\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.2687184512615204, zero_point=45, qscheme=torch.per_channel_affine)\n","  )\n",")\n","FP32 evaluation accuracy: 0.877\n","INT8 evaluation accuracy: 0.876\n","FP32 CPU Inference Latency: 8.68 ms / sample\n","FP32 CUDA Inference Latency: 3.28 ms / sample\n","INT8 CPU Inference Latency: 3.02 ms / sample\n","INT8 JIT CPU Inference Latency: 1.45 ms / sample\n"]}]},{"cell_type":"code","source":["# Epoch: 199 Train Loss: 0.023 Train Acc: 0.993 Eval Loss: 0.644 Eval Acc: 0.877\n","\n","\n","# FP32 evaluation accuracy: 0.877\n","# INT8 evaluation accuracy: 0.876\n","# FP32 CPU Inference Latency: 8.68 ms / sample\n","# FP32 CUDA Inference Latency: 3.28 ms / sample\n","# INT8 CPU Inference Latency: 3.02 ms / sample\n","# INT8 JIT CPU Inference Latency: 1.45 ms / sample\n","\n","\n","# FP32 evaluation accuracy: 0.877\n","# INT8 evaluation accuracy: 0.867\n","# FP32 CPU Inference Latency: 7.35 ms / sample\n","# FP32 CUDA Inference Latency: 3.14 ms / sample\n","# INT8 CPU Inference Latency: 2.70 ms / sample\n","# INT8 JIT CPU Inference Latency: 1.51 ms / sample"],"metadata":{"id":"ihm9WMztGhWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/DeepLearning/PyTorch-Quantization-Aware-Training"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ua19jK9VemJC","executionInfo":{"status":"ok","timestamp":1704700088973,"user_tz":-420,"elapsed":334,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"fcff4601-1645-4aa9-8a54-95641b3d9a62"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DeepLearning/PyTorch-Quantization-Aware-Training\n"]}]},{"cell_type":"code","source":["!python cifar.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgoVbDz_epiB","executionInfo":{"status":"ok","timestamp":1704701938951,"user_tz":-420,"elapsed":451015,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"4634c495-e205-449f-ee11-d6e3b4439281"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Loading Model...\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu1): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n","ResNet(\n","  (conv1): ConvReLU2d(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n","    (1): ReLU(inplace=True)\n","  )\n","  (bn1): Identity()\n","  (relu): Identity()\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n","        (1): Identity()\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n","        (1): Identity()\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n","        (1): Identity()\n","      )\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): ConvReLU2d(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","      )\n","      (bn1): Identity()\n","      (relu1): Identity()\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): Identity()\n","      (skip_add): FloatFunctional(\n","        (activation_post_process): Identity()\n","      )\n","      (relu2): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n","QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n","/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n","  warnings.warn(\n","Training QAT Model...\n","Epoch: 000 Eval Loss: 0.644 Eval Acc: 0.877\n","Epoch: 001 Train Loss: 0.049 Train Acc: 0.983 Eval Loss: 0.697 Eval Acc: 0.863\n","Epoch: 002 Train Loss: 0.053 Train Acc: 0.982 Eval Loss: 0.679 Eval Acc: 0.865\n","Epoch: 003 Train Loss: 0.052 Train Acc: 0.982 Eval Loss: 0.743 Eval Acc: 0.859\n","Epoch: 004 Train Loss: 0.050 Train Acc: 0.982 Eval Loss: 0.669 Eval Acc: 0.867\n","Epoch: 005 Train Loss: 0.044 Train Acc: 0.984 Eval Loss: 0.671 Eval Acc: 0.867\n","Epoch: 006 Train Loss: 0.045 Train Acc: 0.985 Eval Loss: 0.720 Eval Acc: 0.864\n","Epoch: 007 Train Loss: 0.048 Train Acc: 0.983 Eval Loss: 0.692 Eval Acc: 0.861\n","Epoch: 008 Train Loss: 0.046 Train Acc: 0.984 Eval Loss: 0.662 Eval Acc: 0.865\n","Epoch: 009 Train Loss: 0.043 Train Acc: 0.985 Eval Loss: 0.698 Eval Acc: 0.859\n","Epoch: 010 Train Loss: 0.044 Train Acc: 0.984 Eval Loss: 0.669 Eval Acc: 0.868\n","QuantizedResNet18(\n","  (quant): Quantize(scale=tensor([0.0374]), zero_point=tensor([57]), dtype=torch.quint8)\n","  (dequant): DeQuantize()\n","  (model_fp32): ResNet(\n","    (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.05970552936196327, zero_point=0, padding=(3, 3))\n","    (bn1): Identity()\n","    (relu): Identity()\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.029670333489775658, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07888627052307129, zero_point=70, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.09676225483417511, zero_point=49\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.023349393159151077, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.06897860020399094, zero_point=71, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.1006588488817215, zero_point=51\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.02607659250497818, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05778592824935913, zero_point=64, padding=(1, 1))\n","        (bn2): Identity()\n","        (downsample): Sequential(\n","          (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.0446004793047905, zero_point=60)\n","          (1): Identity()\n","        )\n","        (skip_add): QFunctional(\n","          scale=0.08124270290136337, zero_point=62\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.018774038180708885, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.053564462810754776, zero_point=74, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.08430057764053345, zero_point=49\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.019630631431937218, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.03595785051584244, zero_point=71, padding=(1, 1))\n","        (bn2): Identity()\n","        (downsample): Sequential(\n","          (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.0204531941562891, zero_point=63)\n","          (1): Identity()\n","        )\n","        (skip_add): QFunctional(\n","          scale=0.03970267251133919, zero_point=70\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.004558532033115625, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.017844675108790398, zero_point=76, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.025866778567433357, zero_point=43\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.0053982860408723354, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.021611440926790237, zero_point=45, padding=(1, 1))\n","        (bn2): Identity()\n","        (downsample): Sequential(\n","          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.02971774898469448, zero_point=56)\n","          (1): Identity()\n","        )\n","        (skip_add): QFunctional(\n","          scale=0.036818232387304306, zero_point=53\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.0014296014560386539, zero_point=0, padding=(1, 1))\n","        (bn1): Identity()\n","        (relu1): Identity()\n","        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.013044873252511024, zero_point=91, padding=(1, 1))\n","        (bn2): Identity()\n","        (skip_add): QFunctional(\n","          scale=0.028409793972969055, zero_point=27\n","          (activation_post_process): Identity()\n","        )\n","        (relu2): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.27538445591926575, zero_point=45, qscheme=torch.per_channel_affine)\n","  )\n",")\n","FP32 evaluation accuracy: 0.877\n","INT8 evaluation accuracy: 0.867\n","FP32 CPU Inference Latency: 7.35 ms / sample\n","FP32 CUDA Inference Latency: 3.14 ms / sample\n","INT8 CPU Inference Latency: 2.70 ms / sample\n","INT8 JIT CPU Inference Latency: 1.51 ms / sample\n"]}]},{"cell_type":"code","source":["ls saved_models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4onAzoqPfg0F","executionInfo":{"status":"ok","timestamp":1704703037555,"user_tz":-420,"elapsed":513,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"b3c906f9-5d5a-41ae-eba0-b156b8c23da0"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["qat_resnet18_cifar10.pt  resnet18_cifar10.pt  resnet18_quantized_cifar10.pt  \u001b[0m\u001b[01;34mtemporary_backup\u001b[0m/\n"]}]}]}