{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPcAZclqf6Ri/k8NfiZ37yP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"QdjKgtpYHLZZ","executionInfo":{"status":"ok","timestamp":1704374351381,"user_tz":-420,"elapsed":29,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMeWzpL0Gy9-","executionInfo":{"status":"ok","timestamp":1704374377014,"user_tz":-420,"elapsed":25656,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"e833ff3d-fe83-4d8a-d1a8-6cf8082f875a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/DeepLearning\n","# !git clone https://github.com/leimao/PyTorch-Quantization-Aware-Training.git\n","%cd PyTorch-Quantization-Aware-Training"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqKzkOO8G-mt","executionInfo":{"status":"ok","timestamp":1704374377015,"user_tz":-420,"elapsed":29,"user":{"displayName":"Tran Vinh","userId":"16939840668769156240"}},"outputId":"e52d0b89-7c31-4845-ee2d-22ecc9a4323f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DeepLearning\n","/content/drive/MyDrive/DeepLearning/PyTorch-Quantization-Aware-Training\n"]}]},{"cell_type":"code","source":["!pip install -q wandb"],"metadata":{"id":"R-jwtlVurISe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfEr3OY_ofHx","outputId":"c4bf26be-99d3-4c16-c423-b1a84b2395e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtranquocvinh2611\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/DeepLearning/PyTorch-Quantization-Aware-Training/wandb/run-20240104_160756-nm4q6nsr\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtraining_run_2024-01-04_16-07-54\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/tranquocvinh2611/pretrain_resnet18_cifar10\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/tranquocvinh2611/pretrain_resnet18_cifar10/runs/nm4q6nsr\u001b[0m\n","trainable params: 11181642 || all params: 11181642 || trainable%: 100.00\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training Model...\n","Epoch: 000 Eval Loss: 2.456 Eval Acc: 0.114\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Epoch: 001 Train Loss: 2.821 Train Acc: 0.205 Eval Loss: 1.842 Eval Acc: 0.313\n","Epoch: 002 Train Loss: 1.791 Train Acc: 0.327 Eval Loss: 1.615 Eval Acc: 0.408\n","Epoch: 003 Train Loss: 1.639 Train Acc: 0.392 Eval Loss: 1.589 Eval Acc: 0.431\n","Epoch: 004 Train Loss: 1.534 Train Acc: 0.433 Eval Loss: 1.528 Eval Acc: 0.448\n","Epoch: 005 Train Loss: 1.459 Train Acc: 0.464 Eval Loss: 1.733 Eval Acc: 0.466\n","Epoch: 006 Train Loss: 1.367 Train Acc: 0.503 Eval Loss: 1.281 Eval Acc: 0.540\n","Epoch: 007 Train Loss: 1.276 Train Acc: 0.541 Eval Loss: 1.131 Eval Acc: 0.592\n","Epoch: 008 Train Loss: 1.191 Train Acc: 0.574 Eval Loss: 1.101 Eval Acc: 0.613\n","Epoch: 009 Train Loss: 1.135 Train Acc: 0.595 Eval Loss: 1.124 Eval Acc: 0.603\n","Epoch: 010 Train Loss: 1.084 Train Acc: 0.616 Eval Loss: 0.968 Eval Acc: 0.658\n","Epoch: 011 Train Loss: 1.047 Train Acc: 0.630 Eval Loss: 0.982 Eval Acc: 0.651\n","Epoch: 012 Train Loss: 1.026 Train Acc: 0.637 Eval Loss: 0.927 Eval Acc: 0.677\n","Epoch: 013 Train Loss: 0.989 Train Acc: 0.652 Eval Loss: 0.898 Eval Acc: 0.688\n","Epoch: 014 Train Loss: 0.952 Train Acc: 0.666 Eval Loss: 0.939 Eval Acc: 0.680\n","Epoch: 015 Train Loss: 0.932 Train Acc: 0.674 Eval Loss: 0.971 Eval Acc: 0.661\n","Epoch: 016 Train Loss: 0.916 Train Acc: 0.680 Eval Loss: 0.987 Eval Acc: 0.666\n","Epoch: 017 Train Loss: 0.895 Train Acc: 0.690 Eval Loss: 0.841 Eval Acc: 0.714\n","Epoch: 018 Train Loss: 0.872 Train Acc: 0.695 Eval Loss: 0.828 Eval Acc: 0.715\n","Epoch: 019 Train Loss: 0.855 Train Acc: 0.700 Eval Loss: 0.818 Eval Acc: 0.718\n","Epoch: 020 Train Loss: 0.839 Train Acc: 0.706 Eval Loss: 0.851 Eval Acc: 0.708\n","Epoch: 021 Train Loss: 0.819 Train Acc: 0.715 Eval Loss: 0.777 Eval Acc: 0.729\n","Epoch: 022 Train Loss: 0.809 Train Acc: 0.718 Eval Loss: 0.743 Eval Acc: 0.750\n","Epoch: 023 Train Loss: 0.789 Train Acc: 0.725 Eval Loss: 0.760 Eval Acc: 0.738\n","Epoch: 024 Train Loss: 0.784 Train Acc: 0.729 Eval Loss: 0.744 Eval Acc: 0.741\n","Epoch: 025 Train Loss: 0.768 Train Acc: 0.735 Eval Loss: 0.750 Eval Acc: 0.745\n","Epoch: 026 Train Loss: 0.767 Train Acc: 0.734 Eval Loss: 0.729 Eval Acc: 0.757\n","Epoch: 027 Train Loss: 0.746 Train Acc: 0.742 Eval Loss: 0.740 Eval Acc: 0.745\n","Epoch: 028 Train Loss: 0.741 Train Acc: 0.746 Eval Loss: 0.715 Eval Acc: 0.755\n","Epoch: 029 Train Loss: 0.724 Train Acc: 0.749 Eval Loss: 0.666 Eval Acc: 0.767\n","Epoch: 030 Train Loss: 0.719 Train Acc: 0.751 Eval Loss: 0.697 Eval Acc: 0.757\n","Epoch: 031 Train Loss: 0.714 Train Acc: 0.752 Eval Loss: 0.753 Eval Acc: 0.743\n","Epoch: 032 Train Loss: 0.704 Train Acc: 0.756 Eval Loss: 0.785 Eval Acc: 0.732\n","Epoch: 033 Train Loss: 0.692 Train Acc: 0.762 Eval Loss: 0.708 Eval Acc: 0.759\n","Epoch: 034 Train Loss: 0.690 Train Acc: 0.762 Eval Loss: 0.700 Eval Acc: 0.763\n","Epoch: 035 Train Loss: 0.687 Train Acc: 0.763 Eval Loss: 0.744 Eval Acc: 0.744\n","Epoch: 036 Train Loss: 0.675 Train Acc: 0.765 Eval Loss: 0.733 Eval Acc: 0.757\n","Epoch: 037 Train Loss: 0.670 Train Acc: 0.768 Eval Loss: 0.653 Eval Acc: 0.783\n","Epoch: 038 Train Loss: 0.668 Train Acc: 0.771 Eval Loss: 0.651 Eval Acc: 0.787\n","Epoch: 039 Train Loss: 0.656 Train Acc: 0.774 Eval Loss: 0.701 Eval Acc: 0.768\n","Epoch: 040 Train Loss: 0.655 Train Acc: 0.775 Eval Loss: 0.678 Eval Acc: 0.772\n","Epoch: 041 Train Loss: 0.652 Train Acc: 0.775 Eval Loss: 0.670 Eval Acc: 0.776\n","Epoch: 042 Train Loss: 0.653 Train Acc: 0.777 Eval Loss: 0.698 Eval Acc: 0.767\n","Epoch: 043 Train Loss: 0.644 Train Acc: 0.778 Eval Loss: 0.679 Eval Acc: 0.762\n","Epoch: 044 Train Loss: 0.638 Train Acc: 0.782 Eval Loss: 0.701 Eval Acc: 0.767\n","Epoch: 045 Train Loss: 0.636 Train Acc: 0.782 Eval Loss: 0.702 Eval Acc: 0.766\n","Epoch: 046 Train Loss: 0.637 Train Acc: 0.781 Eval Loss: 0.618 Eval Acc: 0.790\n","Epoch: 047 Train Loss: 0.624 Train Acc: 0.785 Eval Loss: 0.696 Eval Acc: 0.754\n","Epoch: 048 Train Loss: 0.628 Train Acc: 0.787 Eval Loss: 0.675 Eval Acc: 0.767\n","Epoch: 049 Train Loss: 0.614 Train Acc: 0.788 Eval Loss: 0.685 Eval Acc: 0.775\n","Epoch: 050 Train Loss: 0.620 Train Acc: 0.788 Eval Loss: 0.657 Eval Acc: 0.785\n","Epoch: 051 Train Loss: 0.616 Train Acc: 0.790 Eval Loss: 0.653 Eval Acc: 0.778\n","Epoch: 052 Train Loss: 0.608 Train Acc: 0.791 Eval Loss: 0.672 Eval Acc: 0.777\n","Epoch: 053 Train Loss: 0.607 Train Acc: 0.790 Eval Loss: 0.723 Eval Acc: 0.759\n","Epoch: 054 Train Loss: 0.601 Train Acc: 0.794 Eval Loss: 0.638 Eval Acc: 0.783\n","Epoch: 055 Train Loss: 0.598 Train Acc: 0.792 Eval Loss: 0.652 Eval Acc: 0.785\n","Epoch: 056 Train Loss: 0.595 Train Acc: 0.795 Eval Loss: 0.658 Eval Acc: 0.787\n","Epoch: 057 Train Loss: 0.593 Train Acc: 0.797 Eval Loss: 0.622 Eval Acc: 0.789\n","Epoch: 058 Train Loss: 0.597 Train Acc: 0.797 Eval Loss: 0.631 Eval Acc: 0.784\n","Epoch: 059 Train Loss: 0.594 Train Acc: 0.796 Eval Loss: 0.621 Eval Acc: 0.790\n","Epoch: 060 Train Loss: 0.590 Train Acc: 0.798 Eval Loss: 0.669 Eval Acc: 0.779\n","Epoch: 061 Train Loss: 0.587 Train Acc: 0.798 Eval Loss: 0.609 Eval Acc: 0.794\n","Epoch: 062 Train Loss: 0.588 Train Acc: 0.799 Eval Loss: 0.627 Eval Acc: 0.789\n","Epoch: 063 Train Loss: 0.578 Train Acc: 0.802 Eval Loss: 0.680 Eval Acc: 0.771\n","Epoch: 064 Train Loss: 0.584 Train Acc: 0.799 Eval Loss: 0.673 Eval Acc: 0.767\n","Epoch: 065 Train Loss: 0.579 Train Acc: 0.802 Eval Loss: 0.590 Eval Acc: 0.796\n","Epoch: 066 Train Loss: 0.581 Train Acc: 0.800 Eval Loss: 0.600 Eval Acc: 0.796\n","Epoch: 067 Train Loss: 0.576 Train Acc: 0.802 Eval Loss: 0.661 Eval Acc: 0.777\n","Epoch: 068 Train Loss: 0.568 Train Acc: 0.805 Eval Loss: 0.634 Eval Acc: 0.794\n","Epoch: 069 Train Loss: 0.577 Train Acc: 0.801 Eval Loss: 0.632 Eval Acc: 0.794\n","Epoch: 070 Train Loss: 0.572 Train Acc: 0.803 Eval Loss: 0.672 Eval Acc: 0.769\n","Epoch: 071 Train Loss: 0.563 Train Acc: 0.807 Eval Loss: 0.633 Eval Acc: 0.796\n","Epoch: 072 Train Loss: 0.562 Train Acc: 0.808 Eval Loss: 0.581 Eval Acc: 0.807\n","Epoch: 073 Train Loss: 0.563 Train Acc: 0.807 Eval Loss: 0.642 Eval Acc: 0.789\n","Epoch: 074 Train Loss: 0.561 Train Acc: 0.807 Eval Loss: 0.656 Eval Acc: 0.780\n","Epoch: 075 Train Loss: 0.565 Train Acc: 0.806 Eval Loss: 0.614 Eval Acc: 0.793\n","Epoch: 076 Train Loss: 0.560 Train Acc: 0.809 Eval Loss: 0.584 Eval Acc: 0.806\n","Epoch: 077 Train Loss: 0.554 Train Acc: 0.811 Eval Loss: 0.591 Eval Acc: 0.801\n","Epoch: 078 Train Loss: 0.559 Train Acc: 0.808 Eval Loss: 0.618 Eval Acc: 0.788\n","Epoch: 079 Train Loss: 0.552 Train Acc: 0.811 Eval Loss: 0.595 Eval Acc: 0.801\n","Epoch: 080 Train Loss: 0.554 Train Acc: 0.811 Eval Loss: 0.681 Eval Acc: 0.772\n","Epoch: 081 Train Loss: 0.557 Train Acc: 0.809 Eval Loss: 0.624 Eval Acc: 0.793\n","Epoch: 082 Train Loss: 0.552 Train Acc: 0.811 Eval Loss: 0.717 Eval Acc: 0.777\n","Epoch: 083 Train Loss: 0.545 Train Acc: 0.812 Eval Loss: 0.604 Eval Acc: 0.799\n","Epoch: 084 Train Loss: 0.549 Train Acc: 0.812 Eval Loss: 0.612 Eval Acc: 0.792\n"]}]},{"cell_type":"code","source":["!python cifar.py"],"metadata":{"id":"pCUIbKBXHE8R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RaliV09BHHjI"},"execution_count":null,"outputs":[]}]}